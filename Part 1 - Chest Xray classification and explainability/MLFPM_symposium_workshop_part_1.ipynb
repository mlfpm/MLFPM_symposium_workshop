{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vmUiIZmp50Tz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import pathlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.metrics import TruePositives, FalsePositives, TrueNegatives, FalseNegatives, BinaryAccuracy, Precision, Recall, AUC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxlvLyDL48j1"
   },
   "source": [
    "# MLFPM symposium\n",
    "### Student workshop - Part 1\n",
    "\n",
    "In this first part, we'll focus on classifying medical images using a few different approaches. We'll use a kaggle dataset containing [chest X-ray images](https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database) from COVID and viral pneumonia patients, and set to classify between the two using a baseline (Principal Component Analysis + Logistic Regression) and a state of the art model (a convolutional neural network called [ChexNet](https://arxiv.org/pdf/1711.05225.pdf)).\n",
    "After comparing and discussing differences in performance, we'll also explore some explainability methods to test how well we can understand how our models make decisions.\n",
    "\n",
    "Let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94sv-bGfnoor",
    "outputId": "0821aed3-e779-4ff8-8f51-7f91d23d761b"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/mlfpm/MLFPM_symposium_workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "w0nCTSmqnqUz"
   },
   "outputs": [],
   "source": [
    "repo_path = \"MLFPM_symposium_workshop/Part 1 - Chest Xray classification and explainability/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pldrm6UJ5SWP"
   },
   "source": [
    "### Download data from Kaggle\n",
    "\n",
    "Run the cells below, and when prompted, use these Kaggle authentication details:\n",
    "\n",
    "username: mlfpmitn\n",
    "\n",
    "key: 3f880a8750f53ce7a6251356d17098e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2MKgfoq61p10",
    "outputId": "db6ed815-a66d-42c2-c9ed-9ca5f33116ce"
   },
   "outputs": [],
   "source": [
    "!pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3xMy-RpO1tBX",
    "outputId": "77f2d135-99c0-475a-be17-201021ebac48"
   },
   "outputs": [],
   "source": [
    "import opendatasets as op\n",
    "op.download(\"https://www.kaggle.com/tawsifurrahman/covid19-radiography-database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QNGIcj15iMC"
   },
   "source": [
    "### Preprocess images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6emGdj61xdw"
   },
   "outputs": [],
   "source": [
    "dataset_folder = os.path.join(\"covid19-radiography-database/COVID-19_Radiography_Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O16hUAF9585J"
   },
   "outputs": [],
   "source": [
    "files_not_important = [\"COVID.metadata.xlsx\",\n",
    "                       \"Lung_Opacity.metadata.xlsx\",\n",
    "                       \"Normal.metadata.xlsx\",\n",
    "                       \"README.md.txt\",\n",
    "                       \"Viral Pneumonia.metadata.xlsx\"]\n",
    "for i in files_not_important:\n",
    "    os.remove(os.path.join(dataset_folder, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3z64vOhg5_30"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "files_not_important = [\n",
    "                       \"COVID/masks\",\n",
    "                       \"Lung_Opacity\",\n",
    "                       \"Normal\",\n",
    "                       \"Viral Pneumonia/masks\"]\n",
    "for i in files_not_important:\n",
    "    shutil.rmtree(os.path.join(dataset_folder, i), ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQ7P7WJB6Cd0"
   },
   "outputs": [],
   "source": [
    "datasetObject = pathlib.Path(os.path.join(dataset_folder))\n",
    "images = list(datasetObject.glob(\"*/*/*.*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zHQD8lnX6GXX",
    "outputId": "760bf09f-3906-44f9-c313-5beef1d4b8a3"
   },
   "outputs": [],
   "source": [
    "image_data_generator = ImageDataGenerator(\n",
    "    rescale = 1/255, vertical_flip= False, horizontal_flip=True, zoom_range=0.1, zca_whitening=False,\n",
    "    samplewise_center=True, samplewise_std_normalization=True, validation_split= 0.1,\n",
    "    rotation_range=0.2)\n",
    "training_dataset = image_data_generator.flow_from_directory(\n",
    "    dataset_folder, target_size = (224, 224), color_mode ='rgb',subset='training', batch_size=8, shuffle=True\n",
    ")\n",
    "validation_dataset = image_data_generator.flow_from_directory(\n",
    "    dataset_folder,  target_size=(224, 224), color_mode = 'rgb', subset='validation', batch_size = 8, shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    (0, 1):\"COVID\",\n",
    "    (1, 0):\"Viral pneumonia\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OXmW9EzJ6Ogt",
    "outputId": "1e19025e-b78f-40eb-b847-985d98878582"
   },
   "outputs": [],
   "source": [
    "print('COVID cases:', (training_dataset.labels == 0).sum())\n",
    "print('Viral pneumonia cases:', (training_dataset.labels == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "id": "Wo9eEUBG6I8K",
    "outputId": "b5011e6a-181f-4334-92af-f133b12e4441"
   },
   "outputs": [],
   "source": [
    "single_batch = training_dataset.next()\n",
    "images = single_batch[0]\n",
    "label = single_batch[1]\n",
    "plt.figure(figsize = (20, 10))\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, (i + 1))\n",
    "    plt.imshow(np.clip(images[i], 0, 1))\n",
    "    plt.title(label_dict[tuple(label[i])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpfR3VgvlreP"
   },
   "source": [
    "## Classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SGj7KZJlreP"
   },
   "source": [
    "### Principal Component Analysis + Logistic Regression baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mUQxyoEClreP"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_Q0sqQFlreP",
    "outputId": "6f72380c-1a71-4902-aa1d-e4d17e12d376"
   },
   "outputs": [],
   "source": [
    "n_train_batches = 200\n",
    "n_val_batches = 50\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "pca_training_dataset = image_data_generator.flow_from_directory(\n",
    "    dataset_folder, target_size = (224, 224), color_mode ='grayscale',subset='training', batch_size=8, shuffle=True\n",
    ")\n",
    "pca_validation_dataset = image_data_generator.flow_from_directory(\n",
    "    dataset_folder, target_size = (224, 224), color_mode ='grayscale',subset='validation', batch_size=8, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "for _ in range(n_train_batches):\n",
    "    images, labels = pca_training_dataset.next()\n",
    "    X_train.extend(images.reshape(8,-1))\n",
    "    y_train.extend(labels)\n",
    "    \n",
    "for _ in range(n_val_batches):  \n",
    "    val_images, val_labels = pca_validation_dataset.next()\n",
    "    X_val.extend(val_images.reshape(8,-1))\n",
    "    y_val.extend(val_labels)\n",
    "    \n",
    "X_train = np.vstack(X_train)\n",
    "X_train -= np.mean(X_train, axis=0)\n",
    "y_train = np.vstack(y_train)\n",
    "X_val = np.vstack(X_val)\n",
    "X_val -= np.mean(X_val, axis=0)\n",
    "y_val = np.vstack(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "MJ7QpboblreP",
    "outputId": "7fa93256-7e79-4943-c103-cfc7bb5d4034"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)\n",
    "pca.fit(X_train)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.bar(range(30), np.cumsum(pca.explained_variance_ratio_[:30]))\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_ylabel(\"Cumulative Explained Variance Ratio\")\n",
    "ax.set_xlabel(\"N. Components\")\n",
    "ax.set_xticks(list(range(0,20,2)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fMiC2dQWlreQ",
    "outputId": "541de358-034b-4965-ea37-726f58b11001"
   },
   "outputs": [],
   "source": [
    "n_components = 32\n",
    "eigenimages = pca.components_[:n_components]\n",
    "\n",
    "# Show the first 9 eigenvectors\n",
    "fig, axes = plt.subplots(3,3,sharex=True,sharey=True,figsize=(16,20))\n",
    "for i in range(9):\n",
    "    axes[i//3][i%3].imshow(eigenimages[i].reshape(224,224), cmap=\"gray\")\n",
    "    axes[i//3][i%3].set_title(\"Eig. {}\".format(i+1))\n",
    "    \n",
    "fig.suptitle(\"First 9 eigenvectors (images) of the PCA projection\", y=0.9, fontsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "2SgDCVf1lreQ",
    "outputId": "d8821fc4-6ce1-4c25-faa5-92ff2cad72a5"
   },
   "outputs": [],
   "source": [
    "pca_embeddings_train = pca.transform(X_train)\n",
    "pca_embeddings_val = pca.transform(X_val)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14,7))\n",
    "\n",
    "ix = np.where(y_train[:,0]==1)\n",
    "neg_ix = np.where(y_train[:,0]==0)\n",
    "axs[0].scatter(pca_embeddings_train[ix, 0], pca_embeddings_train[ix,1], s=80, color=\"#ff7f0e\", label=\"Positive\")\n",
    "axs[0].scatter(pca_embeddings_train[neg_ix, 0], pca_embeddings_train[neg_ix,1], s=80, color=\"#1f77b4\", label=\"Negative\")\n",
    "axs[0].set_title(\"First 2 PCs of training data\")\n",
    "\n",
    "ix = np.where(y_val[:,0]==1)\n",
    "neg_ix = np.where(y_val[:,0]==0)\n",
    "axs[1].scatter(pca_embeddings_train[ix, 0], pca_embeddings_train[ix,1], s=80, c=\"#ff7f0e\")\n",
    "axs[1].scatter(pca_embeddings_train[neg_ix, 0], pca_embeddings_train[neg_ix,1], s=80, color=\"#1f77b4\")\n",
    "axs[1].set_title(\"First 2 PCs of validation data\")\n",
    "fig.legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PExTBwvklreQ",
    "outputId": "e1dd16ef-7cad-4d92-fea6-e5f779be68ce"
   },
   "outputs": [],
   "source": [
    "print(\"Training Logistic Regression model\")\n",
    "lr = LogisticRegression(max_iter=2500)\n",
    "lr.fit(pca_embeddings_train, y_train[:,0])\n",
    "\n",
    "predictions = lr.predict(pca_embeddings_val)\n",
    "\n",
    "print(\"Validation Accuracy: {:.2%}\".format(accuracy_score(y_val[:,0], predictions)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6RD0mEE9LLl"
   },
   "source": [
    "### Build and train a CNN classification model\n",
    "\n",
    "We'll use a CNN, give some details bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hY1LrqUB9KWv"
   },
   "outputs": [],
   "source": [
    "from keras.applications import densenet\n",
    "from keras.initializers import GlorotNormal\n",
    "d = densenet.DenseNet121(weights=None, include_top = False, input_shape = (224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3ksTvG78iMF",
    "outputId": "caa86b4c-06cd-4bf0-a7d9-10c1e259c204"
   },
   "outputs": [],
   "source": [
    "print(d.output_shape)\n",
    "m = tf.keras.layers.Dropout(0.7)(d.output)\n",
    "m = tf.keras.layers.GlobalAveragePooling2D()(m)                         \n",
    "m = tf.keras.layers.Dropout(0.7)(m)\n",
    "m = tf.keras.layers.Dense(2, kernel_initializer=GlorotNormal(),\n",
    "                          activation = 'softmax', kernel_regularizer= tf.keras.regularizers.L2(0.0001),\n",
    "                          bias_regularizer= tf.keras.regularizers.L2(0.0001))(m)\n",
    "m = tf.keras.models.Model(inputs = d.input, outputs = m)\n",
    "\n",
    "m.load_weights(os.path.join(repo_path, \"CheXNet_Keras_0.3.0_raw_weights.h5\"), by_name=True, skip_mismatch=True)\n",
    "\n",
    "for layer in m.layers[:200]:\n",
    "    layer.trainable = False\n",
    "for layer in m.layers[200:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tmH-xSLZ8-CQ"
   },
   "outputs": [],
   "source": [
    "m.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001), \n",
    "    loss = 'categorical_crossentropy', \n",
    "    metrics =  [\n",
    "        TruePositives(name='tp'),\n",
    "        FalsePositives(name='fp'),\n",
    "        TrueNegatives(name='tn'),\n",
    "        FalseNegatives(name='fn'), \n",
    "        'accuracy',\n",
    "        Precision(name='precision'),\n",
    "        Recall(name='recall')\n",
    "      ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBxvA5ExC9V1"
   },
   "outputs": [],
   "source": [
    "ReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.1, \n",
    "    mode = 'min',\n",
    "    patience= 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "_2RpfSECDCtk",
    "outputId": "18b61bc9-663e-4e15-e720-1ffb73bd7b74"
   },
   "outputs": [],
   "source": [
    "history = m.fit(\n",
    "    training_dataset,\n",
    "    validation_data = validation_dataset,\n",
    "    batch_size = 8,\n",
    "    epochs = 1, # Set to ~25 to reach good performance. Takes around 30 min on a GPU environment\n",
    "    callbacks = [ReduceLROnPlateau, tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7, mode = 'min', restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "UWMiGEWdDc5T",
    "outputId": "d2d8451b-e0b0-4963-cc4b-0d1a186911f9"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (10, 5))\n",
    "# plt.plot(history.history['accuracy'], label=\"accuracy\")\n",
    "# plt.plot(history.history['val_accuracy'], label=\"val_accuracy\")\n",
    "\n",
    "# plt.xlabel(\"epochs\")\n",
    "\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "yQwfAWmIK4Wq",
    "outputId": "a2ccfae8-3c76-42bc-863f-b1449baf846a"
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (10, 5))\n",
    "# plt.plot(history.history['loss'], label = \"loss\")\n",
    "# plt.plot(history.history['val_loss'], label = \"val_loss\")\n",
    "\n",
    "# plt.xlabel(\"epochs\")\n",
    "\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUG5435DqHsp"
   },
   "outputs": [],
   "source": [
    "# Load fine tuned weights\n",
    "m.load_weights(os.path.join(repo_path, \"CheXNet_Keras_0.3.0_tuned_weights.h5\"), by_name=True, skip_mismatch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zPX_V8qgK6xa",
    "outputId": "d909377f-20d6-45fc-a707-e8f0ec4bb3d1"
   },
   "outputs": [],
   "source": [
    "m.evaluate(validation_dataset, batch_size = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtxQdwzTrSO0"
   },
   "source": [
    "### Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ygds1gK3rRn6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4Lg7b5-U4yd"
   },
   "source": [
    "### Model interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tunrgJV6U8VB"
   },
   "source": [
    "##### 1. Manual error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3OnwRBTVbH9"
   },
   "outputs": [],
   "source": [
    "# TBD (meeting with a doctor on Monday, to make it a bit more interesting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-uKhqZgU-V4"
   },
   "source": [
    "##### 2. Saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ieH3OUrPVO-x"
   },
   "outputs": [],
   "source": [
    "def get_saliency_map(model, image, class_idx):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        predictions = model(image)\n",
    "        \n",
    "        loss = predictions[:, class_idx]\n",
    "    \n",
    "    # Get the gradients of the loss w.r.t to the input image.\n",
    "    gradient = tape.gradient(loss, image)\n",
    "    \n",
    "    # take maximum across channels\n",
    "    gradient = tf.reduce_max(gradient, axis=-1)\n",
    "    \n",
    "    # convert to numpy\n",
    "    gradient = gradient.numpy()\n",
    "    \n",
    "    # normaliz between 0 and 1\n",
    "    min_val, max_val = np.min(gradient), np.max(gradient)\n",
    "    smap = (gradient - min_val) / (max_val - min_val + tf.keras.backend.epsilon())\n",
    "    \n",
    "    return np.squeeze(smap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B5rG9OA4VPAj"
   },
   "outputs": [],
   "source": [
    "test_image = validation_dataset.next()\n",
    "test_image, test_label = test_image[0][0], int(test_image[1][0][1])\n",
    "\n",
    "saliency = get_saliency_map(m, tf.expand_dims(test_image, axis=0), test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "cfydUGIrlwHV",
    "outputId": "4a86ca5e-4821-4fac-a977-983243fe6cb8"
   },
   "outputs": [],
   "source": [
    "# Visualize image and raw heatmaps\n",
    "\n",
    "fig, (ax1, ax2,) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "ax1.set_title(\"Current test image\")\n",
    "ax1.imshow(np.clip(test_image, 0, 1))\n",
    "\n",
    "ax2.set_title(\"Obtained saliency maps\")\n",
    "ax2.imshow(saliency)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0Bbu-HFU-YO"
   },
   "source": [
    "##### 3. Grad CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzxE0AM0U72M"
   },
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMv0TQg_XHlg"
   },
   "outputs": [],
   "source": [
    "def gradcam_overlay(img, heatmap, alpha=0.4):\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    return superimposed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynd0IsBlK-Jj"
   },
   "outputs": [],
   "source": [
    "test_image = validation_dataset.next()[0][0]\n",
    "\n",
    "gradcam_outputs = make_gradcam_heatmap(\n",
    "    tf.expand_dims(test_image, axis=0), \n",
    "    m, \n",
    "    \"conv5_block16_2_conv\", \n",
    "    pred_index=None\n",
    "    )\n",
    "\n",
    "gradcam_superimposed = gradcam_overlay(test_image, gradcam_outputs, alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "rYUPAJz9VikG",
    "outputId": "1b6fe400-e4c6-47ae-ced4-b93791743ad0"
   },
   "outputs": [],
   "source": [
    "# Visualize image and raw heatmaps\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 16))\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "ax1.set_title(\"Current test image\")\n",
    "ax1.imshow(np.clip(test_image, 0, 1))\n",
    "\n",
    "ax2.set_title(\"Raw Grad CAM heatmap\")\n",
    "ax2.imshow(gradcam_outputs)\n",
    "\n",
    "ax3.set_title(\"Grad CAM superimposed\")\n",
    "ax3.imshow(gradcam_superimposed)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5uyaYgTxanLf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
